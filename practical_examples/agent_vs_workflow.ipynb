{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Workflow vs Agent: Understanding the Key Differences\n",
    "\n",
    "This notebook demonstrates the difference between **Workflows** (traditional deterministic approach) and **Agents** (adaptive LangGraph approach) using a joke generation example.\n",
    "\n",
    "## Key Concepts:\n",
    "- **Workflow**: Fixed, predictable sequence of operations\n",
    "- **Agent**: Dynamic, adaptive decision-making with self-correction capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dependencies loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-latest\", anthropic_api_key=api_key)\n",
    "\n",
    "print(\"âœ… Dependencies loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared_components",
   "metadata": {},
   "source": [
    "## 2. Shared Components\n",
    "\n",
    "Both approaches will use the same state definition and core functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "state_and_functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Shared components defined\n"
     ]
    }
   ],
   "source": [
    "# Shared state definition\n",
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    joke: str\n",
    "    improved_joke: str\n",
    "    final_joke: str\n",
    "    error_message: str\n",
    "    attempt_count: int\n",
    "\n",
    "# Shared core functions\n",
    "def generate_joke(state: State):\n",
    "    \"\"\"Generate initial joke using LLM\"\"\"\n",
    "    msg = llm.invoke(f\"Write a short joke about {state['topic']}\")\n",
    "    return {\"joke\": msg.content}\n",
    "\n",
    "def improve_joke(state: State):\n",
    "    \"\"\"Improve joke by adding wordplay\"\"\"\n",
    "    msg = llm.invoke(f\"Make this joke funnier by adding wordplay: {state['joke']}\")\n",
    "    return {\"improved_joke\": msg.content}\n",
    "\n",
    "def polish_joke(state: State):\n",
    "    \"\"\"Add final polish with surprising twist\"\"\"\n",
    "    msg = llm.invoke(f\"Add a surprising twist to this joke: {state['improved_joke']}\")\n",
    "    return {\"final_joke\": msg.content}\n",
    "\n",
    "def check_punchline(state: State):\n",
    "    \"\"\"Simple quality check for punchline\"\"\"\n",
    "    return \"Pass\" if (\"?\" in state[\"joke\"] or \"!\" in state[\"joke\"]) else \"Fail\"\n",
    "\n",
    "print(\"âœ… Shared components defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "workflow_section",
   "metadata": {},
   "source": [
    "## 3. Workflow Approach ğŸ”„\n",
    "\n",
    "**Characteristics:**\n",
    "- âœ… Deterministic execution\n",
    "- âœ… Predictable flow\n",
    "- âœ… Simple to debug\n",
    "- âŒ Rigid - fails fast\n",
    "- âŒ No self-correction\n",
    "\n",
    "**Flow:** Generate â†’ Quality Gate â†’ (Pass: Improve â†’ Polish) | (Fail: Stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "workflow_implementation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Workflow implementation ready\n"
     ]
    }
   ],
   "source": [
    "def workflow_joke_generator(topic: str) -> State:\n",
    "    \"\"\"\n",
    "    WORKFLOW: Traditional deterministic approach\n",
    "    Fixed sequence with simple conditional logic\n",
    "    \"\"\"\n",
    "    \n",
    "    state = State(\n",
    "        topic=topic, \n",
    "        joke=\"\", \n",
    "        improved_joke=\"\", \n",
    "        final_joke=\"\", \n",
    "        error_message=\"\",\n",
    "        attempt_count=1\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Generate initial joke\n",
    "        print(\"ğŸ”„ WORKFLOW Step 1: Generating initial joke...\")\n",
    "        result = generate_joke(state)\n",
    "        state.update(result)\n",
    "        print(f\"   Generated: {state['joke'][:50]}...\")\n",
    "        \n",
    "        # Step 2: Quality gate (hardcoded business logic)\n",
    "        print(\"ğŸ”„ WORKFLOW Step 2: Checking quality gate...\")\n",
    "        gate_result = check_punchline(state)\n",
    "        \n",
    "        if gate_result == \"Fail\":\n",
    "            state[\"error_message\"] = \"âŒ Joke failed quality gate - no punchline detected!\"\n",
    "            print(f\"   {state['error_message']}\")\n",
    "            return state\n",
    "        \n",
    "        print(\"   âœ… Quality gate passed\")\n",
    "        \n",
    "        # Step 3: Improve joke (only if gate passed)\n",
    "        print(\"ğŸ”„ WORKFLOW Step 3: Improving joke...\")\n",
    "        result = improve_joke(state)\n",
    "        state.update(result)\n",
    "        \n",
    "        # Step 4: Polish joke\n",
    "        print(\"ğŸ”„ WORKFLOW Step 4: Polishing joke...\")\n",
    "        result = polish_joke(state)\n",
    "        state.update(result)\n",
    "        \n",
    "        print(\"âœ… WORKFLOW: Complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        state[\"error_message\"] = f\"âŒ Workflow failed: {str(e)}\"\n",
    "        print(state[\"error_message\"])\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"âœ… Workflow implementation ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent_section",
   "metadata": {},
   "source": [
    "## 4. Agent Approach ğŸ¤–\n",
    "\n",
    "**Characteristics:**\n",
    "- âœ… Adaptive behavior\n",
    "- âœ… Self-correction\n",
    "- âœ… Complex decision trees\n",
    "- âœ… Error recovery\n",
    "- âŒ More complex to debug\n",
    "- âŒ Potentially slower\n",
    "\n",
    "**Flow:** Generate â†’ Smart Gate â†’ (Multiple paths: Improve, Polish, Regenerate, Loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "agent_functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent functions defined\n"
     ]
    }
   ],
   "source": [
    "# Enhanced agent functions with adaptive behavior\n",
    "\n",
    "def agent_generate_joke(state: State):\n",
    "    \"\"\"Agent version with retry logic and attempt tracking\"\"\"\n",
    "    try:\n",
    "        result = generate_joke(state)\n",
    "        print(f\"ğŸ¤– AGENT: Generated joke (attempt {state.get('attempt_count', 1)})\")\n",
    "        print(f\"   Content: {result['joke'][:60]}...\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸ¤– AGENT: Error generating joke, using fallback: {e}\")\n",
    "        return {\"joke\": \"Why did the developer go broke? Because they used up all their cache!\"}\n",
    "\n",
    "def agent_improve_joke(state: State):\n",
    "    \"\"\"Agent version with quality enhancement logic\"\"\"\n",
    "    result = improve_joke(state)\n",
    "    print(\"ğŸ¤– AGENT: Enhanced joke with wordplay\")\n",
    "    \n",
    "    # Agent makes decisions based on intermediate results\n",
    "    if len(result[\"improved_joke\"]) < 50:\n",
    "        print(\"ğŸ¤– AGENT: Joke too short, adding more content...\")\n",
    "        msg = llm.invoke(f\"Make this joke longer and more elaborate: {result['improved_joke']}\")\n",
    "        result[\"improved_joke\"] = msg.content\n",
    "        print(\"   âœ… Enhanced with additional content\")\n",
    "        \n",
    "    return result\n",
    "\n",
    "def agent_polish_joke(state: State):\n",
    "    \"\"\"Agent version with final optimization\"\"\"\n",
    "    result = polish_joke(state)\n",
    "    print(\"ğŸ¤– AGENT: Applied final polish and twist\")\n",
    "    return result\n",
    "\n",
    "def agent_regenerate_joke(state: State):\n",
    "    \"\"\"Agent can regenerate with improved prompting\"\"\"\n",
    "    attempt = state.get('attempt_count', 1) + 1\n",
    "    print(f\"ğŸ¤– AGENT: Regenerating joke (attempt {attempt}) with enhanced prompt...\")\n",
    "    \n",
    "    # More specific prompt based on what failed\n",
    "    enhanced_prompt = f\"\"\"Write a funny joke about {state['topic']} that includes:\n",
    "    - A clear setup and punchline\n",
    "    - Either a question (?) or exclamation (!)\n",
    "    - At least 10 words\n",
    "    Make it clever and engaging.\"\"\"\n",
    "    \n",
    "    msg = llm.invoke(enhanced_prompt)\n",
    "    return {\"joke\": msg.content, \"attempt_count\": attempt}\n",
    "\n",
    "print(\"âœ… Agent functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "agent_routing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent routing logic defined\n"
     ]
    }
   ],
   "source": [
    "def agent_quality_gate(state: State):\n",
    "    \"\"\"Smart routing logic with multiple criteria\"\"\"\n",
    "    joke = state[\"joke\"]\n",
    "    attempt = state.get('attempt_count', 1)\n",
    "    \n",
    "    # Multiple quality checks\n",
    "    has_punchline = \"?\" in joke or \"!\" in joke\n",
    "    has_setup = len(joke.split()) > 5\n",
    "    has_topic = state[\"topic\"].lower() in joke.lower()\n",
    "    is_reasonable_length = 10 < len(joke) < 500\n",
    "    \n",
    "    print(f\"ğŸ¤– AGENT: Quality assessment (attempt {attempt}):\")\n",
    "    print(f\"   Has punchline: {has_punchline}\")\n",
    "    print(f\"   Has setup: {has_setup}\")\n",
    "    print(f\"   Mentions topic: {has_topic}\")\n",
    "    print(f\"   Reasonable length: {is_reasonable_length}\")\n",
    "    \n",
    "    # Adaptive routing logic\n",
    "    if all([has_punchline, has_setup, has_topic, is_reasonable_length]):\n",
    "        print(\"   ğŸ¯ High quality - proceeding to improvement\")\n",
    "        return \"improve\"\n",
    "    elif has_punchline and has_setup:\n",
    "        print(\"   âš¡ Basic quality met - skipping to polish\")\n",
    "        return \"polish\"\n",
    "    elif attempt >= 3:\n",
    "        print(\"   ğŸš« Max attempts reached - proceeding with current joke\")\n",
    "        return \"polish\"\n",
    "    else:\n",
    "        print(\"   ğŸ”„ Quality issues detected - regenerating\")\n",
    "        return \"regenerate\"\n",
    "\n",
    "print(\"âœ… Agent routing logic defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "agent_graph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent graph created and compiled\n"
     ]
    }
   ],
   "source": [
    "def create_agent_joke_generator():\n",
    "    \"\"\"Build the agent graph with adaptive routing\"\"\"\n",
    "    \n",
    "    # Build the agent graph\n",
    "    workflow = StateGraph(State)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"generate\", agent_generate_joke)\n",
    "    workflow.add_node(\"regenerate\", agent_regenerate_joke)\n",
    "    workflow.add_node(\"improve\", agent_improve_joke)\n",
    "    workflow.add_node(\"polish\", agent_polish_joke)\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"generate\")\n",
    "    \n",
    "    # Add conditional edges (agent decision points)\n",
    "    workflow.add_conditional_edges(\n",
    "        \"generate\",\n",
    "        agent_quality_gate,\n",
    "        {\n",
    "            \"improve\": \"improve\",\n",
    "            \"polish\": \"polish\", \n",
    "            \"regenerate\": \"regenerate\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Regenerate can loop back through quality gate\n",
    "    workflow.add_conditional_edges(\n",
    "        \"regenerate\",\n",
    "        agent_quality_gate,\n",
    "        {\n",
    "            \"improve\": \"improve\",\n",
    "            \"polish\": \"polish\",\n",
    "            \"regenerate\": \"regenerate\"  # Potential loop with attempt limit\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Linear flow after quality gate passes\n",
    "    workflow.add_edge(\"improve\", \"polish\")\n",
    "    workflow.add_edge(\"polish\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Create the agent\n",
    "agent = create_agent_joke_generator()\n",
    "print(\"âœ… Agent graph created and compiled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo_section",
   "metadata": {},
   "source": [
    "## 5. Live Comparison Demo ğŸš€\n",
    "\n",
    "Let's run both approaches side-by-side to see the differences in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "workflow_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ”„ WORKFLOW APPROACH - DETERMINISTIC EXECUTION\n",
      "================================================================================\n",
      "ğŸ”„ WORKFLOW Step 1: Generating initial joke...\n",
      "   Generated: Here's a programming joke:\n",
      "\n",
      "Why do programmers pre...\n",
      "ğŸ”„ WORKFLOW Step 2: Checking quality gate...\n",
      "   âœ… Quality gate passed\n",
      "ğŸ”„ WORKFLOW Step 3: Improving joke...\n",
      "ğŸ”„ WORKFLOW Step 4: Polishing joke...\n",
      "âœ… WORKFLOW: Complete!\n",
      "\n",
      "ğŸ“Š WORKFLOW RESULTS:\n",
      "----------------------------------------\n",
      "âœ… Success!\n",
      "ğŸ­ Final result: Here's a twist that adds an unexpected layer to the joke:\n",
      "\n",
      "Why do programmers prefer dark mode?\n",
      "Because light attracts bugs... but plot twist: they actually work at a butterfly sanctuary and need to protect their rare specimen collection! ğŸ¦‹\n",
      "\n",
      "This twist subverts expectations by:\n",
      "1. Making you think it's about code bugs\n",
      "2. Revealing it's about actual insects\n",
      "3. Adding an unexpectedly wholesome reason\n",
      "4. Creating a humorous image of programmers moonlighting as butterfly conservationists\n",
      "\n",
      "Alternative twist:\n",
      "Why do programmers prefer dark mode?\n",
      "Because light attracts bugs... except for Steve, who codes with his monitor at full brightness because he's actually a moth in disguise! ğŸ¦‹\n",
      "\n",
      "This version adds a surreal element while still playing with the original joke's premise!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'topic': 'programming',\n",
       " 'joke': \"Here's a programming joke:\\n\\nWhy do programmers prefer dark mode?\\n\\nBecause light attracts bugs! ğŸª²\",\n",
       " 'improved_joke': 'Here are a few versions with added wordplay:\\n\\n1. Why do programmers prefer dark mode?\\nBecause light attracts bugs - they\\'re trying not to get BYTE! ğŸª²\\n\\n2. Why do programmers prefer dark mode?\\nBecause light attracts bugs, and they don\\'t want their code to be HIGHLIGHTED! ğŸª²\\n\\n3. Why do programmers prefer dark mode?\\nBecause light attracts bugs - it\\'s a TERMINAL condition! ğŸª²\\n\\n4. Why do programmers prefer dark mode?\\nBecause light attracts bugs, and they want to keep their code out of the SPOTLIGHT! ğŸª²\\n\\n5. Why do programmers prefer dark mode?\\nBecause light attracts bugs - they don\\'t want to DEBUG the brightness! ğŸª²\\n\\nThe last one is probably my favorite since it incorporates both the programming term \"debug\" and plays on the light/brightness theme!',\n",
       " 'final_joke': \"Here's a twist that adds an unexpected layer to the joke:\\n\\nWhy do programmers prefer dark mode?\\nBecause light attracts bugs... but plot twist: they actually work at a butterfly sanctuary and need to protect their rare specimen collection! ğŸ¦‹\\n\\nThis twist subverts expectations by:\\n1. Making you think it's about code bugs\\n2. Revealing it's about actual insects\\n3. Adding an unexpectedly wholesome reason\\n4. Creating a humorous image of programmers moonlighting as butterfly conservationists\\n\\nAlternative twist:\\nWhy do programmers prefer dark mode?\\nBecause light attracts bugs... except for Steve, who codes with his monitor at full brightness because he's actually a moth in disguise! ğŸ¦‹\\n\\nThis version adds a surreal element while still playing with the original joke's premise!\",\n",
       " 'error_message': '',\n",
       " 'attempt_count': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the WORKFLOW approach\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ”„ WORKFLOW APPROACH - DETERMINISTIC EXECUTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "topic = \"programming\"\n",
    "workflow_result = workflow_joke_generator(topic)\n",
    "\n",
    "print(\"\\nğŸ“Š WORKFLOW RESULTS:\")\n",
    "print(\"-\" * 40)\n",
    "if workflow_result.get(\"error_message\"):\n",
    "    print(f\"âŒ Error: {workflow_result['error_message']}\")\n",
    "    if workflow_result.get('joke'):\n",
    "        print(f\"ğŸ­ Initial joke: {workflow_result['joke']}\")\n",
    "else:\n",
    "    print(f\"âœ… Success!\")\n",
    "    print(f\"ğŸ­ Final result: {workflow_result.get('final_joke', 'No final joke')}\")\n",
    "\n",
    "workflow_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "agent_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ¤– AGENT APPROACH - ADAPTIVE EXECUTION\n",
      "================================================================================\n",
      "ğŸ¤– AGENT: Generated joke (attempt 1)\n",
      "   Content: Here's a programming joke:\n",
      "\n",
      "Why do programmers prefer dark m...\n",
      "ğŸ¤– AGENT: Quality assessment (attempt 1):\n",
      "   Has punchline: True\n",
      "   Has setup: True\n",
      "   Mentions topic: True\n",
      "   Reasonable length: True\n",
      "   ğŸ¯ High quality - proceeding to improvement\n",
      "ğŸ¤– AGENT: Enhanced joke with wordplay\n",
      "ğŸ¤– AGENT: Applied final polish and twist\n",
      "\n",
      "ğŸ“Š AGENT RESULTS:\n",
      "----------------------------------------\n",
      "âœ… Success!\n",
      "ğŸ­ Final result: Here's a twist version that subverts expectations:\n",
      "\n",
      "Why do programmers prefer dark mode?\n",
      "Because light attracts bugs - or so they thought, until they discovered their rubber duck debugger glows in the dark! ğŸ¦†âœ¨\n",
      "\n",
      "This twist is fun because it:\n",
      "1. Sets up the familiar premise about avoiding bugs\n",
      "2. Then reveals programmers accidentally created a new bug-attracting problem with their glowing rubber duck debugging tool\n",
      "3. References the common programming practice of rubber duck debugging\n",
      "4. Creates an absurd mental image of a programmer in the dark with a glowing duck\n",
      "\n",
      "Alternative twist:\n",
      "Why do programmers prefer dark mode?\n",
      "Because light attracts bugs - until they realized their RGB gaming keyboard was turning their workspace into a bug disco party! ğŸ•ºğŸ’ƒ\n",
      "\n",
      "This version plays on the stereotype of programmers with fancy RGB setups while maintaining the bug theme.\n",
      "ğŸ”„ Total attempts: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'topic': 'programming',\n",
       " 'joke': \"Here's a programming joke:\\n\\nWhy do programmers prefer dark mode?\\n\\nBecause light attracts bugs! ğŸª²\",\n",
       " 'improved_joke': 'Here are a few wordplay-enhanced versions:\\n\\n1. Why do programmers prefer dark mode?\\nBecause light attracts bugs - and they\\'re trying to avoid de-bugging! ğŸª²\\n\\n2. Why do programmers prefer dark mode?\\nBecause light attracts bugs - they don\\'t want to HIGHLIGHT their problems! ğŸª²\\n\\n3. Why do programmers prefer dark mode?\\nBecause light attracts bugs - and they want to keep their code out of the SPOTLIGHT! ğŸª²\\n\\n4. Why do programmers prefer dark mode?\\nBecause light attracts bugs - they\\'re trying to stay in their COMPILE-ment zone! ğŸª²\\n\\nThe last one is my favorite since it plays on \"compliment/complement\" and \"compile\" - all programmer-relevant terms!',\n",
       " 'final_joke': \"Here's a twist version that subverts expectations:\\n\\nWhy do programmers prefer dark mode?\\nBecause light attracts bugs - or so they thought, until they discovered their rubber duck debugger glows in the dark! ğŸ¦†âœ¨\\n\\nThis twist is fun because it:\\n1. Sets up the familiar premise about avoiding bugs\\n2. Then reveals programmers accidentally created a new bug-attracting problem with their glowing rubber duck debugging tool\\n3. References the common programming practice of rubber duck debugging\\n4. Creates an absurd mental image of a programmer in the dark with a glowing duck\\n\\nAlternative twist:\\nWhy do programmers prefer dark mode?\\nBecause light attracts bugs - until they realized their RGB gaming keyboard was turning their workspace into a bug disco party! ğŸ•ºğŸ’ƒ\\n\\nThis version plays on the stereotype of programmers with fancy RGB setups while maintaining the bug theme.\",\n",
       " 'error_message': '',\n",
       " 'attempt_count': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the AGENT approach\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ¤– AGENT APPROACH - ADAPTIVE EXECUTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "initial_state = {\n",
    "    \"topic\": \"programming\", \n",
    "    \"joke\": \"\", \n",
    "    \"improved_joke\": \"\", \n",
    "    \"final_joke\": \"\", \n",
    "    \"error_message\": \"\",\n",
    "    \"attempt_count\": 1\n",
    "}\n",
    "\n",
    "agent_result = agent.invoke(initial_state)\n",
    "\n",
    "print(\"\\nğŸ“Š AGENT RESULTS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"âœ… Success!\")\n",
    "print(f\"ğŸ­ Final result: {agent_result.get('final_joke', 'No final joke')}\")\n",
    "print(f\"ğŸ”„ Total attempts: {agent_result.get('attempt_count', 1)}\")\n",
    "\n",
    "agent_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison_analysis",
   "metadata": {},
   "source": [
    "## 6. Side-by-Side Analysis ğŸ“Š\n",
    "\n",
    "Let's test both approaches with a \"difficult\" topic to see how they handle edge cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stress_test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Testing topic: 'quantum computing'\n",
      "================================================================================\n",
      "ğŸ”„ WORKFLOW:\n",
      "ğŸ”„ WORKFLOW Step 1: Generating initial joke...\n",
      "   Generated: Here's a quantum computing joke:\n",
      "\n",
      "Why did the quan...\n",
      "ğŸ”„ WORKFLOW Step 2: Checking quality gate...\n",
      "   âœ… Quality gate passed\n",
      "ğŸ”„ WORKFLOW Step 3: Improving joke...\n",
      "ğŸ”„ WORKFLOW Step 4: Polishing joke...\n",
      "âœ… WORKFLOW: Complete!\n",
      "\n",
      "ğŸ¤– AGENT:\n",
      "ğŸ¤– AGENT: Generated joke (attempt 1)\n",
      "   Content: Here's a quantum computing joke:\n",
      "\n",
      "Why don't quantum computer...\n",
      "ğŸ¤– AGENT: Quality assessment (attempt 1):\n",
      "   Has punchline: True\n",
      "   Has setup: True\n",
      "   Mentions topic: True\n",
      "   Reasonable length: True\n",
      "   ğŸ¯ High quality - proceeding to improvement\n",
      "ğŸ¤– AGENT: Enhanced joke with wordplay\n",
      "ğŸ¤– AGENT: Applied final polish and twist\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š COMPARISON SUMMARY\n",
      "================================================================================\n",
      "â±ï¸  Execution Time:\n",
      "   Workflow: 11.98s\n",
      "   Agent:    10.72s\n",
      "\n",
      "âœ… Success Rate:\n",
      "   Workflow: âœ… Success\n",
      "   Agent:    âœ… Success (adaptive recovery)\n",
      "\n",
      "ğŸ”„ Adaptability:\n",
      "   Workflow: Fixed path, fails at quality gate\n",
      "   Agent:    1 attempts, self-correcting\n"
     ]
    }
   ],
   "source": [
    "def compare_approaches(topic: str):\n",
    "    \"\"\"Run both approaches and compare results\"\"\"\n",
    "    \n",
    "    print(f\"ğŸ¯ Testing topic: '{topic}'\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Workflow test\n",
    "    print(\"ğŸ”„ WORKFLOW:\")\n",
    "    workflow_start = __import__('time').time()\n",
    "    workflow_result = workflow_joke_generator(topic)\n",
    "    workflow_time = __import__('time').time() - workflow_start\n",
    "    \n",
    "    workflow_success = not bool(workflow_result.get(\"error_message\"))\n",
    "    \n",
    "    # Agent test  \n",
    "    print(\"\\nğŸ¤– AGENT:\")\n",
    "    agent_start = __import__('time').time()\n",
    "    agent_result = agent.invoke({\n",
    "        \"topic\": topic, \"joke\": \"\", \"improved_joke\": \"\", \n",
    "        \"final_joke\": \"\", \"error_message\": \"\", \"attempt_count\": 1\n",
    "    })\n",
    "    agent_time = __import__('time').time() - agent_start\n",
    "    \n",
    "    # Comparison summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ“Š COMPARISON SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"â±ï¸  Execution Time:\")\n",
    "    print(f\"   Workflow: {workflow_time:.2f}s\")\n",
    "    print(f\"   Agent:    {agent_time:.2f}s\")\n",
    "    \n",
    "    print(f\"\\nâœ… Success Rate:\")\n",
    "    print(f\"   Workflow: {'âœ… Success' if workflow_success else 'âŒ Failed'}\")\n",
    "    print(f\"   Agent:    âœ… Success (adaptive recovery)\")\n",
    "    \n",
    "    print(f\"\\nğŸ”„ Adaptability:\")\n",
    "    print(f\"   Workflow: Fixed path, fails at quality gate\")\n",
    "    print(f\"   Agent:    {agent_result.get('attempt_count', 1)} attempts, self-correcting\")\n",
    "    \n",
    "    return workflow_result, agent_result\n",
    "\n",
    "# Test with a potentially challenging topic\n",
    "workflow_res, agent_res = compare_approaches(\"quantum computing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "key_differences",
   "metadata": {},
   "source": [
    "## 7. Key Differences Summary ğŸ“‹\n",
    "\n",
    "| Aspect | Workflow ğŸ”„ | Agent ğŸ¤– |\n",
    "|--------|-------------|----------|\n",
    "| **Execution** | Deterministic, linear | Adaptive, non-linear |\n",
    "| **Decision Making** | Hardcoded conditional logic | Dynamic routing based on state |\n",
    "| **Error Handling** | Fail-fast, no recovery | Self-correction and retry |\n",
    "| **Complexity** | Simple, predictable | Complex, intelligent |\n",
    "| **Performance** | Fast, efficient | Slower, more thorough |\n",
    "| **Debugging** | Easy to trace | Harder to predict |\n",
    "| **Maintenance** | Simple updates | Complex state management |\n",
    "| **Use Cases** | Stable, well-defined processes | Dynamic, evolving requirements |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "when_to_use",
   "metadata": {},
   "source": [
    "## 8. When to Use Each Approach ğŸ¤”\n",
    "\n",
    "### Use **Workflows** when:\n",
    "- âœ… Requirements are well-defined and stable\n",
    "- âœ… Simple, linear processing is sufficient  \n",
    "- âœ… Predictability and performance are critical\n",
    "- âœ… Easy debugging and maintenance are important\n",
    "- âœ… Compliance and auditability are required\n",
    "\n",
    "**Examples:** Data ETL pipelines, report generation, simple approval processes\n",
    "\n",
    "### Use **Agents** when:\n",
    "- âœ… Requirements are complex or evolving\n",
    "- âœ… Need adaptive behavior and error recovery\n",
    "- âœ… Multiple decision paths are required\n",
    "- âœ… Self-optimization adds significant value\n",
    "- âœ… Handling unpredictable inputs\n",
    "\n",
    "**Examples:** Content generation, customer service, research tasks, complex problem-solving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cost_analysis",
   "metadata": {},
   "source": [
    "## 9. Cost and Performance Analysis ğŸ’°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cost_analysis_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’° ESTIMATED COSTS:\n",
      "----------------------------------------\n",
      "Workflow: 3 calls Ã— $0.003 = $0.009\n",
      "Agent:    4 calls Ã— $0.003 = $0.012\n",
      "\n",
      "Cost difference: $0.003 (+33.3%)\n",
      "\n",
      "ğŸ“ˆ TRADE-OFFS:\n",
      "----------------------------------------\n",
      "â€¢ Both succeeded - evaluate if agent's adaptability worth extra cost\n",
      "â€¢ Consider failure rates in production when choosing approach\n"
     ]
    }
   ],
   "source": [
    "def estimate_costs(workflow_result, agent_result):\n",
    "    \"\"\"\n",
    "    Rough cost estimation based on LLM calls\n",
    "    Note: This is a simplified example - real costs depend on token usage\n",
    "    \"\"\"\n",
    "    \n",
    "    # Typical workflow: 3 LLM calls (generate, improve, polish)\n",
    "    workflow_calls = 3 if not workflow_result.get('error_message') else 1\n",
    "    \n",
    "    # Agent calls depend on routing decisions\n",
    "    agent_attempts = agent_result.get('attempt_count', 1)\n",
    "    # Base calls: generate + routing, then improve + polish (or just polish)\n",
    "    agent_calls = agent_attempts + (3 if 'improved_joke' in agent_result else 2)\n",
    "    \n",
    "    # Rough cost per call (example - actual costs vary)\n",
    "    cost_per_call = 0.003  # ~$0.003 per call for simple jokes\n",
    "    \n",
    "    workflow_cost = workflow_calls * cost_per_call\n",
    "    agent_cost = agent_calls * cost_per_call\n",
    "    \n",
    "    print(\"ğŸ’° ESTIMATED COSTS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Workflow: {workflow_calls} calls Ã— ${cost_per_call:.3f} = ${workflow_cost:.3f}\")\n",
    "    print(f\"Agent:    {agent_calls} calls Ã— ${cost_per_call:.3f} = ${agent_cost:.3f}\")\n",
    "    print(f\"\\nCost difference: ${abs(agent_cost - workflow_cost):.3f} ({((agent_cost/workflow_cost - 1)*100):+.1f}%)\")\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ TRADE-OFFS:\")\n",
    "    print(\"-\" * 40)\n",
    "    if workflow_result.get('error_message'):\n",
    "        print(\"â€¢ Workflow failed - Agent provided working solution despite higher cost\")\n",
    "        print(\"â€¢ Agent's self-correction justified the additional expense\")\n",
    "    else:\n",
    "        print(\"â€¢ Both succeeded - evaluate if agent's adaptability worth extra cost\")\n",
    "        print(\"â€¢ Consider failure rates in production when choosing approach\")\n",
    "\n",
    "# Run cost analysis\n",
    "estimate_costs(workflow_res, agent_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Recommendations ğŸ¯\n",
    "\n",
    "### For Your SWE Team:\n",
    "\n",
    "1. **Start Simple**: Begin with workflows for well-understood processes\n",
    "2. **Evolve to Agents**: When requirements become complex or unpredictable\n",
    "3. **Hybrid Approach**: Use workflows for stable components, agents for dynamic parts\n",
    "4. **Monitor Costs**: Agent flexibility comes at computational cost\n",
    "5. **Testing Strategy**: Agents require more sophisticated testing due to non-deterministic behavior\n",
    "\n",
    "### Architecture Decision Framework:\n",
    "\n",
    "```\n",
    "Requirements Stable + Simple Logic â†’ Workflow\n",
    "Requirements Dynamic + Complex Logic â†’ Agent  \n",
    "Cost Sensitive + Predictable â†’ Workflow\n",
    "Quality Critical + Adaptive â†’ Agent\n",
    "```\n",
    "\n",
    "The key is matching the tool to the problem complexity and business requirements! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
